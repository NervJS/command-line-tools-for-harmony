<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>API Reference: neural_network_runtime/neural_network_core.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">API Reference
   &#160;<span id="projectnumber">5.0.5.165</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('neural__network__core_8h.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">neural_network_core.h File Reference<div class="ingroups"><a class="el" href="group___neural_nework_runtime.html">NeuralNeworkRuntime</a></div></div>  </div>
</div><!--header-->
<div class="contents">

<p>Defines the Neural Network Core APIs. The AI inference framework uses the Native APIs provided by Neural Network Core to compile models and perform inference and computing on acceleration hardware.  
<a href="#details">More...</a></p>
<div class="textblock"><code>#include &quot;<a class="el" href="neural__network__runtime__type_8h_source.html">neural_network_runtime_type.h</a>&quot;</code><br />
</div>
<p><a href="neural__network__core_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga642ce605311075cd5d5cc5b527fee3b6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga642ce605311075cd5d5cc5b527fee3b6">OH_NNCompilation_Construct</a> (const <a class="el" href="group___neural_nework_runtime.html#ga4169d4a60707eae47f924a19a77db0a1">OH_NNModel</a> *model)</td></tr>
<tr class="memdesc:ga642ce605311075cd5d5cc5b527fee3b6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a compilation instance of the <a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> type.  <a href="group___neural_nework_runtime.html#ga642ce605311075cd5d5cc5b527fee3b6">More...</a><br /></td></tr>
<tr class="separator:ga642ce605311075cd5d5cc5b527fee3b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gace3c05942fb3649efd3ab712e35a2ef3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gace3c05942fb3649efd3ab712e35a2ef3">OH_NNCompilation_ConstructWithOfflineModelFile</a> (const char *modelPath)</td></tr>
<tr class="memdesc:gace3c05942fb3649efd3ab712e35a2ef3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a compilation instance based on an offline model file.  <a href="group___neural_nework_runtime.html#gace3c05942fb3649efd3ab712e35a2ef3">More...</a><br /></td></tr>
<tr class="separator:gace3c05942fb3649efd3ab712e35a2ef3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaeb58a0dce316a5b1c5fe281e277e7830"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaeb58a0dce316a5b1c5fe281e277e7830">OH_NNCompilation_ConstructWithOfflineModelBuffer</a> (const void *modelBuffer, size_t modelSize)</td></tr>
<tr class="memdesc:gaeb58a0dce316a5b1c5fe281e277e7830"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a compilation instance based on an offline model file buffer.  <a href="group___neural_nework_runtime.html#gaeb58a0dce316a5b1c5fe281e277e7830">More...</a><br /></td></tr>
<tr class="separator:gaeb58a0dce316a5b1c5fe281e277e7830"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaad1fae1380a70f07920c2aad41b38f8b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaad1fae1380a70f07920c2aad41b38f8b">OH_NNCompilation_ConstructForCache</a> ()</td></tr>
<tr class="memdesc:gaad1fae1380a70f07920c2aad41b38f8b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a empty compilation instance for restoration from cache later.  <a href="group___neural_nework_runtime.html#gaad1fae1380a70f07920c2aad41b38f8b">More...</a><br /></td></tr>
<tr class="separator:gaad1fae1380a70f07920c2aad41b38f8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga22d3a939459ea07c94ed1b4cc3458314"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga22d3a939459ea07c94ed1b4cc3458314">OH_NNCompilation_ExportCacheToBuffer</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, const void *buffer, size_t length, size_t *modelSize)</td></tr>
<tr class="memdesc:ga22d3a939459ea07c94ed1b4cc3458314"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exports the cache to a given buffer.  <a href="group___neural_nework_runtime.html#ga22d3a939459ea07c94ed1b4cc3458314">More...</a><br /></td></tr>
<tr class="separator:ga22d3a939459ea07c94ed1b4cc3458314"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1c2c203801d794b98769fd655e24c302"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga1c2c203801d794b98769fd655e24c302">OH_NNCompilation_ImportCacheFromBuffer</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, const void *buffer, size_t modelSize)</td></tr>
<tr class="memdesc:ga1c2c203801d794b98769fd655e24c302"><td class="mdescLeft">&#160;</td><td class="mdescRight">Imports the cache from a given buffer.  <a href="group___neural_nework_runtime.html#ga1c2c203801d794b98769fd655e24c302">More...</a><br /></td></tr>
<tr class="separator:ga1c2c203801d794b98769fd655e24c302"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad22c665884bc562e63141bd553d081e8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gad22c665884bc562e63141bd553d081e8">OH_NNCompilation_AddExtensionConfig</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, const char *configName, const void *configValue, const size_t configValueSize)</td></tr>
<tr class="memdesc:gad22c665884bc562e63141bd553d081e8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds an extension config for a custom hardware attribute.  <a href="group___neural_nework_runtime.html#gad22c665884bc562e63141bd553d081e8">More...</a><br /></td></tr>
<tr class="separator:gad22c665884bc562e63141bd553d081e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga7a49f89704bc0ca23718089ccdb7f4bc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga7a49f89704bc0ca23718089ccdb7f4bc">OH_NNCompilation_SetDevice</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, size_t deviceID)</td></tr>
<tr class="memdesc:ga7a49f89704bc0ca23718089ccdb7f4bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specifies the device for model compilation and computing.  <a href="group___neural_nework_runtime.html#ga7a49f89704bc0ca23718089ccdb7f4bc">More...</a><br /></td></tr>
<tr class="separator:ga7a49f89704bc0ca23718089ccdb7f4bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf39f535a7f493c13b3da544b11808e64"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaf39f535a7f493c13b3da544b11808e64">OH_NNCompilation_SetCache</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, const char *cachePath, uint32_t version)</td></tr>
<tr class="memdesc:gaf39f535a7f493c13b3da544b11808e64"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the cache directory and version of the compiled model.  <a href="group___neural_nework_runtime.html#gaf39f535a7f493c13b3da544b11808e64">More...</a><br /></td></tr>
<tr class="separator:gaf39f535a7f493c13b3da544b11808e64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf7924c5da4c40acd7ffacacec273ab5d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaf7924c5da4c40acd7ffacacec273ab5d">OH_NNCompilation_SetPerformanceMode</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, <a class="el" href="group___neural_nework_runtime.html#ga2ea6daeb95ee5bea81f97a5d9aeef5bf">OH_NN_PerformanceMode</a> performanceMode)</td></tr>
<tr class="memdesc:gaf7924c5da4c40acd7ffacacec273ab5d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the performance mode for model computing.  <a href="group___neural_nework_runtime.html#gaf7924c5da4c40acd7ffacacec273ab5d">More...</a><br /></td></tr>
<tr class="separator:gaf7924c5da4c40acd7ffacacec273ab5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6299bad43aee5562ab729211b46cb121"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga6299bad43aee5562ab729211b46cb121">OH_NNCompilation_SetPriority</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, <a class="el" href="group___neural_nework_runtime.html#ga5ae0ed09b49e98f608f47ac4fe9ecb07">OH_NN_Priority</a> priority)</td></tr>
<tr class="memdesc:ga6299bad43aee5562ab729211b46cb121"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the model computing priority.  <a href="group___neural_nework_runtime.html#ga6299bad43aee5562ab729211b46cb121">More...</a><br /></td></tr>
<tr class="separator:ga6299bad43aee5562ab729211b46cb121"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2ca3b78ee42ff11890d52923238eebb2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga2ca3b78ee42ff11890d52923238eebb2">OH_NNCompilation_EnableFloat16</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation, bool enableFloat16)</td></tr>
<tr class="memdesc:ga2ca3b78ee42ff11890d52923238eebb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Enables float16 for computing.  <a href="group___neural_nework_runtime.html#ga2ca3b78ee42ff11890d52923238eebb2">More...</a><br /></td></tr>
<tr class="separator:ga2ca3b78ee42ff11890d52923238eebb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8a65c2ea5b8ce232f5acefbf064c1a9b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga8a65c2ea5b8ce232f5acefbf064c1a9b">OH_NNCompilation_Build</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation)</td></tr>
<tr class="memdesc:ga8a65c2ea5b8ce232f5acefbf064c1a9b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compiles a model.  <a href="group___neural_nework_runtime.html#ga8a65c2ea5b8ce232f5acefbf064c1a9b">More...</a><br /></td></tr>
<tr class="separator:ga8a65c2ea5b8ce232f5acefbf064c1a9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae3ded5e4036db67e17313cbe7275f906"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gae3ded5e4036db67e17313cbe7275f906">OH_NNCompilation_Destroy</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> **compilation)</td></tr>
<tr class="memdesc:gae3ded5e4036db67e17313cbe7275f906"><td class="mdescLeft">&#160;</td><td class="mdescRight">Releases the <b>Compilation</b> object.  <a href="group___neural_nework_runtime.html#gae3ded5e4036db67e17313cbe7275f906">More...</a><br /></td></tr>
<tr class="separator:gae3ded5e4036db67e17313cbe7275f906"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga69293f465289045fd6ce120d8f7fb58c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga69293f465289045fd6ce120d8f7fb58c">OH_NNTensorDesc_Create</a> ()</td></tr>
<tr class="memdesc:ga69293f465289045fd6ce120d8f7fb58c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates an <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> instance.  <a href="group___neural_nework_runtime.html#ga69293f465289045fd6ce120d8f7fb58c">More...</a><br /></td></tr>
<tr class="separator:ga69293f465289045fd6ce120d8f7fb58c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4e299cd1a5d0f2c1e2507f86b880fb60"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga4e299cd1a5d0f2c1e2507f86b880fb60">OH_NNTensorDesc_Destroy</a> (<a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> **tensorDesc)</td></tr>
<tr class="memdesc:ga4e299cd1a5d0f2c1e2507f86b880fb60"><td class="mdescLeft">&#160;</td><td class="mdescRight">Releases an <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> instance.  <a href="group___neural_nework_runtime.html#ga4e299cd1a5d0f2c1e2507f86b880fb60">More...</a><br /></td></tr>
<tr class="separator:ga4e299cd1a5d0f2c1e2507f86b880fb60"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaca0cfcef499c386c2a49725798a55ed2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaca0cfcef499c386c2a49725798a55ed2">OH_NNTensorDesc_SetName</a> (<a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, const char *name)</td></tr>
<tr class="memdesc:gaca0cfcef499c386c2a49725798a55ed2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the name of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#gaca0cfcef499c386c2a49725798a55ed2">More...</a><br /></td></tr>
<tr class="separator:gaca0cfcef499c386c2a49725798a55ed2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6a4c3c06e3c85c9169da0d2645d7ef9e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga6a4c3c06e3c85c9169da0d2645d7ef9e">OH_NNTensorDesc_GetName</a> (const <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, const char **name)</td></tr>
<tr class="memdesc:ga6a4c3c06e3c85c9169da0d2645d7ef9e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the name of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#ga6a4c3c06e3c85c9169da0d2645d7ef9e">More...</a><br /></td></tr>
<tr class="separator:ga6a4c3c06e3c85c9169da0d2645d7ef9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5da36f7eb8fa101edb9965439f728ac6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga5da36f7eb8fa101edb9965439f728ac6">OH_NNTensorDesc_SetDataType</a> (<a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, <a class="el" href="group___neural_nework_runtime.html#ga917dcf1cb1e7bb745ccf984e9e67940e">OH_NN_DataType</a> dataType)</td></tr>
<tr class="memdesc:ga5da36f7eb8fa101edb9965439f728ac6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the data type of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#ga5da36f7eb8fa101edb9965439f728ac6">More...</a><br /></td></tr>
<tr class="separator:ga5da36f7eb8fa101edb9965439f728ac6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaea89367832dba35f842c526d0325bc5b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaea89367832dba35f842c526d0325bc5b">OH_NNTensorDesc_GetDataType</a> (const <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, <a class="el" href="group___neural_nework_runtime.html#ga917dcf1cb1e7bb745ccf984e9e67940e">OH_NN_DataType</a> *dataType)</td></tr>
<tr class="memdesc:gaea89367832dba35f842c526d0325bc5b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the data type of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#gaea89367832dba35f842c526d0325bc5b">More...</a><br /></td></tr>
<tr class="separator:gaea89367832dba35f842c526d0325bc5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2050fd8e0fac1a8a234629c43c80fad3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga2050fd8e0fac1a8a234629c43c80fad3">OH_NNTensorDesc_SetShape</a> (<a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, const int32_t *shape, size_t shapeLength)</td></tr>
<tr class="memdesc:ga2050fd8e0fac1a8a234629c43c80fad3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the shape of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#ga2050fd8e0fac1a8a234629c43c80fad3">More...</a><br /></td></tr>
<tr class="separator:ga2050fd8e0fac1a8a234629c43c80fad3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae2c7ad5cf0133ec216d66d168aedc10f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gae2c7ad5cf0133ec216d66d168aedc10f">OH_NNTensorDesc_GetShape</a> (const <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, int32_t **shape, size_t *shapeLength)</td></tr>
<tr class="memdesc:gae2c7ad5cf0133ec216d66d168aedc10f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the shape of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#gae2c7ad5cf0133ec216d66d168aedc10f">More...</a><br /></td></tr>
<tr class="separator:gae2c7ad5cf0133ec216d66d168aedc10f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga066b3fdcea563ab96e9d8fadf9df3c8d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga066b3fdcea563ab96e9d8fadf9df3c8d">OH_NNTensorDesc_SetFormat</a> (<a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, <a class="el" href="group___neural_nework_runtime.html#ga467f4b3c524b8ec4ebf3c86d680f7f59">OH_NN_Format</a> format)</td></tr>
<tr class="memdesc:ga066b3fdcea563ab96e9d8fadf9df3c8d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the format of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#ga066b3fdcea563ab96e9d8fadf9df3c8d">More...</a><br /></td></tr>
<tr class="separator:ga066b3fdcea563ab96e9d8fadf9df3c8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga54953cf8b797779898660fd50e550623"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga54953cf8b797779898660fd50e550623">OH_NNTensorDesc_GetFormat</a> (const <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, <a class="el" href="group___neural_nework_runtime.html#ga467f4b3c524b8ec4ebf3c86d680f7f59">OH_NN_Format</a> *format)</td></tr>
<tr class="memdesc:ga54953cf8b797779898660fd50e550623"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the format of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#ga54953cf8b797779898660fd50e550623">More...</a><br /></td></tr>
<tr class="separator:ga54953cf8b797779898660fd50e550623"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gada602068be210bc6c7f778f0931e5848"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gada602068be210bc6c7f778f0931e5848">OH_NNTensorDesc_GetElementCount</a> (const <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, size_t *elementCount)</td></tr>
<tr class="memdesc:gada602068be210bc6c7f778f0931e5848"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the element count of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#gada602068be210bc6c7f778f0931e5848">More...</a><br /></td></tr>
<tr class="separator:gada602068be210bc6c7f778f0931e5848"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabeca8077942b547ad6160807f38332c1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gabeca8077942b547ad6160807f38332c1">OH_NNTensorDesc_GetByteSize</a> (const <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, size_t *byteSize)</td></tr>
<tr class="memdesc:gabeca8077942b547ad6160807f38332c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the byte size of a <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#gabeca8077942b547ad6160807f38332c1">More...</a><br /></td></tr>
<tr class="separator:gabeca8077942b547ad6160807f38332c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga724c81fe4a2e48021fd545b3c072ba50"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga724c81fe4a2e48021fd545b3c072ba50">OH_NNTensor_Create</a> (size_t deviceID, <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc)</td></tr>
<tr class="memdesc:ga724c81fe4a2e48021fd545b3c072ba50"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> instance from <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#ga724c81fe4a2e48021fd545b3c072ba50">More...</a><br /></td></tr>
<tr class="separator:ga724c81fe4a2e48021fd545b3c072ba50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad658b50239b119baece25c7470ccf403"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gad658b50239b119baece25c7470ccf403">OH_NNTensor_CreateWithSize</a> (size_t deviceID, <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, size_t size)</td></tr>
<tr class="memdesc:gad658b50239b119baece25c7470ccf403"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> instance with specified size and <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#gad658b50239b119baece25c7470ccf403">More...</a><br /></td></tr>
<tr class="separator:gad658b50239b119baece25c7470ccf403"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafd7fac565ba766422257e1525dc416ce"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gafd7fac565ba766422257e1525dc416ce">OH_NNTensor_CreateWithFd</a> (size_t deviceID, <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *tensorDesc, int fd, size_t size, size_t offset)</td></tr>
<tr class="memdesc:gafd7fac565ba766422257e1525dc416ce"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> instance with specified file descriptor and <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a>.  <a href="group___neural_nework_runtime.html#gafd7fac565ba766422257e1525dc416ce">More...</a><br /></td></tr>
<tr class="separator:gafd7fac565ba766422257e1525dc416ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga33d9d392ba17947c578b099961d32789"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga33d9d392ba17947c578b099961d32789">OH_NNTensor_Destroy</a> (<a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> **tensor)</td></tr>
<tr class="memdesc:ga33d9d392ba17947c578b099961d32789"><td class="mdescLeft">&#160;</td><td class="mdescRight">Releases a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> instance.  <a href="group___neural_nework_runtime.html#ga33d9d392ba17947c578b099961d32789">More...</a><br /></td></tr>
<tr class="separator:ga33d9d392ba17947c578b099961d32789"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaaeb03b1a5cd44ba29f71b5814acb73b2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaaeb03b1a5cd44ba29f71b5814acb73b2">OH_NNTensor_GetTensorDesc</a> (const <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *tensor)</td></tr>
<tr class="memdesc:gaaeb03b1a5cd44ba29f71b5814acb73b2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the <a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> instance of a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a>.  <a href="group___neural_nework_runtime.html#gaaeb03b1a5cd44ba29f71b5814acb73b2">More...</a><br /></td></tr>
<tr class="separator:gaaeb03b1a5cd44ba29f71b5814acb73b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8ac1491aa7df59382a46ffceb7302638"><td class="memItemLeft" align="right" valign="top">void *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga8ac1491aa7df59382a46ffceb7302638">OH_NNTensor_GetDataBuffer</a> (const <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *tensor)</td></tr>
<tr class="memdesc:ga8ac1491aa7df59382a46ffceb7302638"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the data buffer of a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a>.  <a href="group___neural_nework_runtime.html#ga8ac1491aa7df59382a46ffceb7302638">More...</a><br /></td></tr>
<tr class="separator:ga8ac1491aa7df59382a46ffceb7302638"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga581e19d403376f61434edd1d86b30c11"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga581e19d403376f61434edd1d86b30c11">OH_NNTensor_GetFd</a> (const <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *tensor, int *fd)</td></tr>
<tr class="memdesc:ga581e19d403376f61434edd1d86b30c11"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the file descriptor of the shared memory of a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a>.  <a href="group___neural_nework_runtime.html#ga581e19d403376f61434edd1d86b30c11">More...</a><br /></td></tr>
<tr class="separator:ga581e19d403376f61434edd1d86b30c11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac5f825923842d3484b66e799b6bda650"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gac5f825923842d3484b66e799b6bda650">OH_NNTensor_GetSize</a> (const <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *tensor, size_t *size)</td></tr>
<tr class="memdesc:gac5f825923842d3484b66e799b6bda650"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the size of the shared memory of a <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a>.  <a href="group___neural_nework_runtime.html#gac5f825923842d3484b66e799b6bda650">More...</a><br /></td></tr>
<tr class="separator:gac5f825923842d3484b66e799b6bda650"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae4d72419b8e7fc0ac70bf91ab7510ecb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gae4d72419b8e7fc0ac70bf91ab7510ecb">OH_NNTensor_GetOffset</a> (const <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *tensor, size_t *offset)</td></tr>
<tr class="memdesc:gae4d72419b8e7fc0ac70bf91ab7510ecb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the data offset of a tensor.  <a href="group___neural_nework_runtime.html#gae4d72419b8e7fc0ac70bf91ab7510ecb">More...</a><br /></td></tr>
<tr class="separator:gae4d72419b8e7fc0ac70bf91ab7510ecb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaca3d4495ef04ebb7e32400bbf9d61c5d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaca3d4495ef04ebb7e32400bbf9d61c5d">OH_NNExecutor_Construct</a> (<a class="el" href="group___neural_nework_runtime.html#ga717fa252bcbce3942c2ec2b25238492b">OH_NNCompilation</a> *compilation)</td></tr>
<tr class="memdesc:gaca3d4495ef04ebb7e32400bbf9d61c5d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates an executor instance of the <a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> type.  <a href="group___neural_nework_runtime.html#gaca3d4495ef04ebb7e32400bbf9d61c5d">More...</a><br /></td></tr>
<tr class="separator:gaca3d4495ef04ebb7e32400bbf9d61c5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadcc8c5d6bec42ffb06d2ce3b6698207d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gadcc8c5d6bec42ffb06d2ce3b6698207d">OH_NNExecutor_GetOutputShape</a> (<a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, uint32_t outputIndex, int32_t **shape, uint32_t *shapeLength)</td></tr>
<tr class="memdesc:gadcc8c5d6bec42ffb06d2ce3b6698207d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the dimension information about the output tensor.  <a href="group___neural_nework_runtime.html#gadcc8c5d6bec42ffb06d2ce3b6698207d">More...</a><br /></td></tr>
<tr class="separator:gadcc8c5d6bec42ffb06d2ce3b6698207d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8d7fade61b14d54446f7076e688c30f2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga8d7fade61b14d54446f7076e688c30f2">OH_NNExecutor_Destroy</a> (<a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> **executor)</td></tr>
<tr class="memdesc:ga8d7fade61b14d54446f7076e688c30f2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroys an executor instance to release the memory occupied by the executor.  <a href="group___neural_nework_runtime.html#ga8d7fade61b14d54446f7076e688c30f2">More...</a><br /></td></tr>
<tr class="separator:ga8d7fade61b14d54446f7076e688c30f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga15cc92e6c5cb825b154c367108bc28cc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga15cc92e6c5cb825b154c367108bc28cc">OH_NNExecutor_GetInputCount</a> (const <a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, size_t *inputCount)</td></tr>
<tr class="memdesc:ga15cc92e6c5cb825b154c367108bc28cc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the input tensor count.  <a href="group___neural_nework_runtime.html#ga15cc92e6c5cb825b154c367108bc28cc">More...</a><br /></td></tr>
<tr class="separator:ga15cc92e6c5cb825b154c367108bc28cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf679893bb2413ce72229b310c91e3663"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaf679893bb2413ce72229b310c91e3663">OH_NNExecutor_GetOutputCount</a> (const <a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, size_t *outputCount)</td></tr>
<tr class="memdesc:gaf679893bb2413ce72229b310c91e3663"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the output tensor count.  <a href="group___neural_nework_runtime.html#gaf679893bb2413ce72229b310c91e3663">More...</a><br /></td></tr>
<tr class="separator:gaf679893bb2413ce72229b310c91e3663"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad55eda40f5087c543911469a6e003916"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gad55eda40f5087c543911469a6e003916">OH_NNExecutor_CreateInputTensorDesc</a> (const <a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, size_t index)</td></tr>
<tr class="memdesc:gad55eda40f5087c543911469a6e003916"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates an input tensor descriptor with its index.  <a href="group___neural_nework_runtime.html#gad55eda40f5087c543911469a6e003916">More...</a><br /></td></tr>
<tr class="separator:gad55eda40f5087c543911469a6e003916"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9f8d0428fc8f7568e7569e8bf9e3eb4e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga15da798ec7d8a9e924f172a252fcf080">NN_TensorDesc</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga9f8d0428fc8f7568e7569e8bf9e3eb4e">OH_NNExecutor_CreateOutputTensorDesc</a> (const <a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, size_t index)</td></tr>
<tr class="memdesc:ga9f8d0428fc8f7568e7569e8bf9e3eb4e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates an output tensor descriptor with its index.  <a href="group___neural_nework_runtime.html#ga9f8d0428fc8f7568e7569e8bf9e3eb4e">More...</a><br /></td></tr>
<tr class="separator:ga9f8d0428fc8f7568e7569e8bf9e3eb4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga91e0d9066ddd07ed2e12d2bd3971c9fa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga91e0d9066ddd07ed2e12d2bd3971c9fa">OH_NNExecutor_GetInputDimRange</a> (const <a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, size_t index, size_t **minInputDims, size_t **maxInputDims, size_t *shapeLength)</td></tr>
<tr class="memdesc:ga91e0d9066ddd07ed2e12d2bd3971c9fa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the dimension ranges of an input tensor.  <a href="group___neural_nework_runtime.html#ga91e0d9066ddd07ed2e12d2bd3971c9fa">More...</a><br /></td></tr>
<tr class="separator:ga91e0d9066ddd07ed2e12d2bd3971c9fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2a5f79e766f1c4a7eab4dcbd8d582743"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga2a5f79e766f1c4a7eab4dcbd8d582743">OH_NNExecutor_SetOnRunDone</a> (<a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, <a class="el" href="group___neural_nework_runtime.html#ga0686487b4c80b6bd0d686fa1c08b4c8c">NN_OnRunDone</a> onRunDone)</td></tr>
<tr class="memdesc:ga2a5f79e766f1c4a7eab4dcbd8d582743"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the callback function handle for the post-process when the asynchronous execution has been done.  <a href="group___neural_nework_runtime.html#ga2a5f79e766f1c4a7eab4dcbd8d582743">More...</a><br /></td></tr>
<tr class="separator:ga2a5f79e766f1c4a7eab4dcbd8d582743"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf2fbdb20804b7f4839abc838413bc241"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#gaf2fbdb20804b7f4839abc838413bc241">OH_NNExecutor_SetOnServiceDied</a> (<a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, <a class="el" href="group___neural_nework_runtime.html#ga965dabbf39f75570925be38b8d0c8f76">NN_OnServiceDied</a> onServiceDied)</td></tr>
<tr class="memdesc:gaf2fbdb20804b7f4839abc838413bc241"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the callback function handle for the post-process when the device driver service is dead during asynchronous execution.  <a href="group___neural_nework_runtime.html#gaf2fbdb20804b7f4839abc838413bc241">More...</a><br /></td></tr>
<tr class="separator:gaf2fbdb20804b7f4839abc838413bc241"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga77aca3467cfda5a05042be320d34e90c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga77aca3467cfda5a05042be320d34e90c">OH_NNExecutor_RunSync</a> (<a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *inputTensor[], size_t inputCount, <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *outputTensor[], size_t outputCount)</td></tr>
<tr class="memdesc:ga77aca3467cfda5a05042be320d34e90c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Synchronous execution of the model inference.  <a href="group___neural_nework_runtime.html#ga77aca3467cfda5a05042be320d34e90c">More...</a><br /></td></tr>
<tr class="separator:ga77aca3467cfda5a05042be320d34e90c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga199e78f7de09248707a4aaa3bf76d07a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga199e78f7de09248707a4aaa3bf76d07a">OH_NNExecutor_RunAsync</a> (<a class="el" href="group___neural_nework_runtime.html#ga93fd7e632b29ec5174a09e138478ce78">OH_NNExecutor</a> *executor, <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *inputTensor[], size_t inputCount, <a class="el" href="group___neural_nework_runtime.html#ga36df49080d9305767e96668e948a8f3b">NN_Tensor</a> *outputTensor[], size_t outputCount, int32_t <a class="el" href="group___usb_ddk.html#gab5627d8d8b095c198e2523c44ca380ac">timeout</a>, void *userData)</td></tr>
<tr class="memdesc:ga199e78f7de09248707a4aaa3bf76d07a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Asynchronous execution of the model inference.  <a href="group___neural_nework_runtime.html#ga199e78f7de09248707a4aaa3bf76d07a">More...</a><br /></td></tr>
<tr class="separator:ga199e78f7de09248707a4aaa3bf76d07a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga66c11e4935abaa6710a1d8eb4d09395f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga66c11e4935abaa6710a1d8eb4d09395f">OH_NNDevice_GetAllDevicesID</a> (const size_t **allDevicesID, uint32_t *deviceCount)</td></tr>
<tr class="memdesc:ga66c11e4935abaa6710a1d8eb4d09395f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the IDs of all devices connected.  <a href="group___neural_nework_runtime.html#ga66c11e4935abaa6710a1d8eb4d09395f">More...</a><br /></td></tr>
<tr class="separator:ga66c11e4935abaa6710a1d8eb4d09395f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga27d205f26b9e1dd1a0a5bb2e058341a9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga27d205f26b9e1dd1a0a5bb2e058341a9">OH_NNDevice_GetName</a> (size_t deviceID, const char **name)</td></tr>
<tr class="memdesc:ga27d205f26b9e1dd1a0a5bb2e058341a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the name of the specified device.  <a href="group___neural_nework_runtime.html#ga27d205f26b9e1dd1a0a5bb2e058341a9">More...</a><br /></td></tr>
<tr class="separator:ga27d205f26b9e1dd1a0a5bb2e058341a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga06a27876b3f3bf0170031b26c4d04f62"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group___neural_nework_runtime.html#ga28c9d17051cc5833d0b749c0b61e1823">OH_NN_ReturnCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_nework_runtime.html#ga06a27876b3f3bf0170031b26c4d04f62">OH_NNDevice_GetType</a> (size_t deviceID, <a class="el" href="group___neural_nework_runtime.html#gae99ff81dfe03a24f714261009b5d2bff">OH_NN_DeviceType</a> *deviceType)</td></tr>
<tr class="memdesc:ga06a27876b3f3bf0170031b26c4d04f62"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtains the type information of the specified device.  <a href="group___neural_nework_runtime.html#ga06a27876b3f3bf0170031b26c4d04f62">More...</a><br /></td></tr>
<tr class="separator:ga06a27876b3f3bf0170031b26c4d04f62"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Defines the Neural Network Core APIs. The AI inference framework uses the Native APIs provided by Neural Network Core to compile models and perform inference and computing on acceleration hardware. </p>
<p>Note: Currently, the APIs of Neural Network Core do not support multi-thread calling. <br />
 include "neural_network_runtime/neural_network_core.h"  libneural_network_core.so  NeuralNetworkRuntimeKit  SystemCapability.Ai.NeuralNetworkRuntime </p><dl class="section since"><dt>Since</dt><dd>11 </dd></dl>
<dl class="section version"><dt>Version</dt><dd>1.0 </dd></dl>

<p class="definition">Definition in file <a class="el" href="neural__network__core_8h_source.html">neural_network_core.h</a>.</p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_2511da406b16e1fa783b3ce7e7a6681e.html">neural_network_runtime</a></li><li class="navelem"><a class="el" href="neural__network__core_8h.html">neural_network_core.h</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
